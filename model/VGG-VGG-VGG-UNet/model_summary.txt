DataParallel(
  (module): UNet(
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (up): Upsample(scale_factor=2.0, mode=bilinear)
    (conv0_0): VGGBlock(
      (relu): ReLU(inplace=True)
      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (conv1_0): VGGBlock(
      (relu): ReLU(inplace=True)
      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (conv2_0): VGGBlock(
      (relu): ReLU(inplace=True)
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (conv3_0): VGGBlock(
      (relu): ReLU(inplace=True)
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (conv4_0): VGGBlock(
      (relu): ReLU(inplace=True)
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (conv3_1): VGGBlock(
      (relu): ReLU(inplace=True)
      (conv1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (conv2_2): VGGBlock(
      (relu): ReLU(inplace=True)
      (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (conv1_3): VGGBlock(
      (relu): ReLU(inplace=True)
      (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (conv0_4): VGGBlock(
      (relu): ReLU(inplace=True)
      (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (final): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
  )
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 128, 256]             896
            Conv2d-2         [-1, 32, 128, 256]             896
       BatchNorm2d-3         [-1, 32, 128, 256]              64
       BatchNorm2d-4         [-1, 32, 128, 256]              64
              ReLU-5         [-1, 32, 128, 256]               0
              ReLU-6         [-1, 32, 128, 256]               0
            Conv2d-7         [-1, 32, 128, 256]           9,248
       BatchNorm2d-8         [-1, 32, 128, 256]              64
              ReLU-9         [-1, 32, 128, 256]               0
         VGGBlock-10         [-1, 32, 128, 256]               0
        MaxPool2d-11          [-1, 32, 64, 128]               0
           Conv2d-12         [-1, 32, 128, 256]           9,248
      BatchNorm2d-13         [-1, 32, 128, 256]              64
             ReLU-14         [-1, 32, 128, 256]               0
         VGGBlock-15         [-1, 32, 128, 256]               0
        MaxPool2d-16          [-1, 32, 64, 128]               0
           Conv2d-17          [-1, 64, 64, 128]          18,496
      BatchNorm2d-18          [-1, 64, 64, 128]             128
             ReLU-19          [-1, 64, 64, 128]               0
           Conv2d-20          [-1, 64, 64, 128]          18,496
      BatchNorm2d-21          [-1, 64, 64, 128]             128
             ReLU-22          [-1, 64, 64, 128]               0
           Conv2d-23          [-1, 64, 64, 128]          36,928
      BatchNorm2d-24          [-1, 64, 64, 128]             128
             ReLU-25          [-1, 64, 64, 128]               0
         VGGBlock-26          [-1, 64, 64, 128]               0
        MaxPool2d-27           [-1, 64, 32, 64]               0
           Conv2d-28          [-1, 64, 64, 128]          36,928
      BatchNorm2d-29          [-1, 64, 64, 128]             128
             ReLU-30          [-1, 64, 64, 128]               0
         VGGBlock-31          [-1, 64, 64, 128]               0
        MaxPool2d-32           [-1, 64, 32, 64]               0
           Conv2d-33          [-1, 128, 32, 64]          73,856
      BatchNorm2d-34          [-1, 128, 32, 64]             256
             ReLU-35          [-1, 128, 32, 64]               0
           Conv2d-36          [-1, 128, 32, 64]          73,856
      BatchNorm2d-37          [-1, 128, 32, 64]             256
             ReLU-38          [-1, 128, 32, 64]               0
           Conv2d-39          [-1, 128, 32, 64]         147,584
      BatchNorm2d-40          [-1, 128, 32, 64]             256
             ReLU-41          [-1, 128, 32, 64]               0
         VGGBlock-42          [-1, 128, 32, 64]               0
        MaxPool2d-43          [-1, 128, 16, 32]               0
           Conv2d-44          [-1, 128, 32, 64]         147,584
      BatchNorm2d-45          [-1, 128, 32, 64]             256
             ReLU-46          [-1, 128, 32, 64]               0
         VGGBlock-47          [-1, 128, 32, 64]               0
        MaxPool2d-48          [-1, 128, 16, 32]               0
           Conv2d-49          [-1, 256, 16, 32]         295,168
      BatchNorm2d-50          [-1, 256, 16, 32]             512
             ReLU-51          [-1, 256, 16, 32]               0
           Conv2d-52          [-1, 256, 16, 32]         295,168
      BatchNorm2d-53          [-1, 256, 16, 32]             512
             ReLU-54          [-1, 256, 16, 32]               0
           Conv2d-55          [-1, 256, 16, 32]         590,080
      BatchNorm2d-56          [-1, 256, 16, 32]             512
             ReLU-57          [-1, 256, 16, 32]               0
         VGGBlock-58          [-1, 256, 16, 32]               0
        MaxPool2d-59           [-1, 256, 8, 16]               0
           Conv2d-60           [-1, 512, 8, 16]       1,180,160
      BatchNorm2d-61           [-1, 512, 8, 16]           1,024
             ReLU-62           [-1, 512, 8, 16]               0
           Conv2d-63          [-1, 256, 16, 32]         590,080
      BatchNorm2d-64          [-1, 256, 16, 32]             512
             ReLU-65          [-1, 256, 16, 32]               0
         VGGBlock-66          [-1, 256, 16, 32]               0
        MaxPool2d-67           [-1, 256, 8, 16]               0
           Conv2d-68           [-1, 512, 8, 16]       1,180,160
      BatchNorm2d-69           [-1, 512, 8, 16]           1,024
             ReLU-70           [-1, 512, 8, 16]               0
           Conv2d-71           [-1, 512, 8, 16]       2,359,808
      BatchNorm2d-72           [-1, 512, 8, 16]           1,024
             ReLU-73           [-1, 512, 8, 16]               0
         VGGBlock-74           [-1, 512, 8, 16]               0
         Upsample-75          [-1, 512, 16, 32]               0
           Conv2d-76           [-1, 512, 8, 16]       2,359,808
      BatchNorm2d-77           [-1, 512, 8, 16]           1,024
             ReLU-78           [-1, 512, 8, 16]               0
         VGGBlock-79           [-1, 512, 8, 16]               0
         Upsample-80          [-1, 512, 16, 32]               0
           Conv2d-81          [-1, 256, 16, 32]       1,769,728
      BatchNorm2d-82          [-1, 256, 16, 32]             512
             ReLU-83          [-1, 256, 16, 32]               0
           Conv2d-84          [-1, 256, 16, 32]         590,080
      BatchNorm2d-85          [-1, 256, 16, 32]             512
             ReLU-86          [-1, 256, 16, 32]               0
         VGGBlock-87          [-1, 256, 16, 32]               0
         Upsample-88          [-1, 256, 32, 64]               0
           Conv2d-89          [-1, 256, 16, 32]       1,769,728
      BatchNorm2d-90          [-1, 256, 16, 32]             512
             ReLU-91          [-1, 256, 16, 32]               0
           Conv2d-92          [-1, 256, 16, 32]         590,080
      BatchNorm2d-93          [-1, 256, 16, 32]             512
             ReLU-94          [-1, 256, 16, 32]               0
         VGGBlock-95          [-1, 256, 16, 32]               0
         Upsample-96          [-1, 256, 32, 64]               0
           Conv2d-97          [-1, 128, 32, 64]         442,496
      BatchNorm2d-98          [-1, 128, 32, 64]             256
             ReLU-99          [-1, 128, 32, 64]               0
          Conv2d-100          [-1, 128, 32, 64]         147,584
     BatchNorm2d-101          [-1, 128, 32, 64]             256
            ReLU-102          [-1, 128, 32, 64]               0
        VGGBlock-103          [-1, 128, 32, 64]               0
        Upsample-104         [-1, 128, 64, 128]               0
          Conv2d-105          [-1, 128, 32, 64]         442,496
     BatchNorm2d-106          [-1, 128, 32, 64]             256
          Conv2d-107          [-1, 64, 64, 128]         110,656
            ReLU-108          [-1, 128, 32, 64]               0
          Conv2d-109          [-1, 128, 32, 64]         147,584
     BatchNorm2d-110          [-1, 64, 64, 128]             128
            ReLU-111          [-1, 64, 64, 128]               0
     BatchNorm2d-112          [-1, 128, 32, 64]             256
            ReLU-113          [-1, 128, 32, 64]               0
        VGGBlock-114          [-1, 128, 32, 64]               0
        Upsample-115         [-1, 128, 64, 128]               0
          Conv2d-116          [-1, 64, 64, 128]          36,928
          Conv2d-117          [-1, 64, 64, 128]         110,656
     BatchNorm2d-118          [-1, 64, 64, 128]             128
     BatchNorm2d-119          [-1, 64, 64, 128]             128
            ReLU-120          [-1, 64, 64, 128]               0
        VGGBlock-121          [-1, 64, 64, 128]               0
        Upsample-122         [-1, 64, 128, 256]               0
            ReLU-123          [-1, 64, 64, 128]               0
          Conv2d-124          [-1, 64, 64, 128]          36,928
     BatchNorm2d-125          [-1, 64, 64, 128]             128
            ReLU-126          [-1, 64, 64, 128]               0
        VGGBlock-127          [-1, 64, 64, 128]               0
        Upsample-128         [-1, 64, 128, 256]               0
          Conv2d-129         [-1, 32, 128, 256]          27,680
          Conv2d-130         [-1, 32, 128, 256]          27,680
     BatchNorm2d-131         [-1, 32, 128, 256]              64
     BatchNorm2d-132         [-1, 32, 128, 256]              64
            ReLU-133         [-1, 32, 128, 256]               0
          Conv2d-134         [-1, 32, 128, 256]           9,248
            ReLU-135         [-1, 32, 128, 256]               0
          Conv2d-136         [-1, 32, 128, 256]           9,248
     BatchNorm2d-137         [-1, 32, 128, 256]              64
            ReLU-138         [-1, 32, 128, 256]               0
        VGGBlock-139         [-1, 32, 128, 256]               0
     BatchNorm2d-140         [-1, 32, 128, 256]              64
            ReLU-141         [-1, 32, 128, 256]               0
        VGGBlock-142         [-1, 32, 128, 256]               0
          Conv2d-143          [-1, 2, 128, 256]              66
          Conv2d-144          [-1, 2, 128, 256]              66
            UNet-145          [-1, 2, 128, 256]               0
            UNet-146          [-1, 2, 128, 256]               0
================================================================
Total params: 15,705,156
Trainable params: 15,705,156
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.38
Forward/backward pass size (MB): 496.50
Params size (MB): 59.91
Estimated Total Size (MB): 556.79
----------------------------------------------------------------


==================MODEL PARAMETER==================
module.conv0_0.conv1.weight 	 torch.Size([32, 3, 3, 3])
module.conv0_0.conv1.bias 	 torch.Size([32])
module.conv0_0.bn1.weight 	 torch.Size([32])
module.conv0_0.bn1.bias 	 torch.Size([32])
module.conv0_0.bn1.running_mean 	 torch.Size([32])
module.conv0_0.bn1.running_var 	 torch.Size([32])
module.conv0_0.bn1.num_batches_tracked 	 torch.Size([])
module.conv0_0.conv2.weight 	 torch.Size([32, 32, 3, 3])
module.conv0_0.conv2.bias 	 torch.Size([32])
module.conv0_0.bn2.weight 	 torch.Size([32])
module.conv0_0.bn2.bias 	 torch.Size([32])
module.conv0_0.bn2.running_mean 	 torch.Size([32])
module.conv0_0.bn2.running_var 	 torch.Size([32])
module.conv0_0.bn2.num_batches_tracked 	 torch.Size([])
module.conv1_0.conv1.weight 	 torch.Size([64, 32, 3, 3])
module.conv1_0.conv1.bias 	 torch.Size([64])
module.conv1_0.bn1.weight 	 torch.Size([64])
module.conv1_0.bn1.bias 	 torch.Size([64])
module.conv1_0.bn1.running_mean 	 torch.Size([64])
module.conv1_0.bn1.running_var 	 torch.Size([64])
module.conv1_0.bn1.num_batches_tracked 	 torch.Size([])
module.conv1_0.conv2.weight 	 torch.Size([64, 64, 3, 3])
module.conv1_0.conv2.bias 	 torch.Size([64])
module.conv1_0.bn2.weight 	 torch.Size([64])
module.conv1_0.bn2.bias 	 torch.Size([64])
module.conv1_0.bn2.running_mean 	 torch.Size([64])
module.conv1_0.bn2.running_var 	 torch.Size([64])
module.conv1_0.bn2.num_batches_tracked 	 torch.Size([])
module.conv2_0.conv1.weight 	 torch.Size([128, 64, 3, 3])
module.conv2_0.conv1.bias 	 torch.Size([128])
module.conv2_0.bn1.weight 	 torch.Size([128])
module.conv2_0.bn1.bias 	 torch.Size([128])
module.conv2_0.bn1.running_mean 	 torch.Size([128])
module.conv2_0.bn1.running_var 	 torch.Size([128])
module.conv2_0.bn1.num_batches_tracked 	 torch.Size([])
module.conv2_0.conv2.weight 	 torch.Size([128, 128, 3, 3])
module.conv2_0.conv2.bias 	 torch.Size([128])
module.conv2_0.bn2.weight 	 torch.Size([128])
module.conv2_0.bn2.bias 	 torch.Size([128])
module.conv2_0.bn2.running_mean 	 torch.Size([128])
module.conv2_0.bn2.running_var 	 torch.Size([128])
module.conv2_0.bn2.num_batches_tracked 	 torch.Size([])
module.conv3_0.conv1.weight 	 torch.Size([256, 128, 3, 3])
module.conv3_0.conv1.bias 	 torch.Size([256])
module.conv3_0.bn1.weight 	 torch.Size([256])
module.conv3_0.bn1.bias 	 torch.Size([256])
module.conv3_0.bn1.running_mean 	 torch.Size([256])
module.conv3_0.bn1.running_var 	 torch.Size([256])
module.conv3_0.bn1.num_batches_tracked 	 torch.Size([])
module.conv3_0.conv2.weight 	 torch.Size([256, 256, 3, 3])
module.conv3_0.conv2.bias 	 torch.Size([256])
module.conv3_0.bn2.weight 	 torch.Size([256])
module.conv3_0.bn2.bias 	 torch.Size([256])
module.conv3_0.bn2.running_mean 	 torch.Size([256])
module.conv3_0.bn2.running_var 	 torch.Size([256])
module.conv3_0.bn2.num_batches_tracked 	 torch.Size([])
module.conv4_0.conv1.weight 	 torch.Size([512, 256, 3, 3])
module.conv4_0.conv1.bias 	 torch.Size([512])
module.conv4_0.bn1.weight 	 torch.Size([512])
module.conv4_0.bn1.bias 	 torch.Size([512])
module.conv4_0.bn1.running_mean 	 torch.Size([512])
module.conv4_0.bn1.running_var 	 torch.Size([512])
module.conv4_0.bn1.num_batches_tracked 	 torch.Size([])
module.conv4_0.conv2.weight 	 torch.Size([512, 512, 3, 3])
module.conv4_0.conv2.bias 	 torch.Size([512])
module.conv4_0.bn2.weight 	 torch.Size([512])
module.conv4_0.bn2.bias 	 torch.Size([512])
module.conv4_0.bn2.running_mean 	 torch.Size([512])
module.conv4_0.bn2.running_var 	 torch.Size([512])
module.conv4_0.bn2.num_batches_tracked 	 torch.Size([])
module.conv3_1.conv1.weight 	 torch.Size([256, 768, 3, 3])
module.conv3_1.conv1.bias 	 torch.Size([256])
module.conv3_1.bn1.weight 	 torch.Size([256])
module.conv3_1.bn1.bias 	 torch.Size([256])
module.conv3_1.bn1.running_mean 	 torch.Size([256])
module.conv3_1.bn1.running_var 	 torch.Size([256])
module.conv3_1.bn1.num_batches_tracked 	 torch.Size([])
module.conv3_1.conv2.weight 	 torch.Size([256, 256, 3, 3])
module.conv3_1.conv2.bias 	 torch.Size([256])
module.conv3_1.bn2.weight 	 torch.Size([256])
module.conv3_1.bn2.bias 	 torch.Size([256])
module.conv3_1.bn2.running_mean 	 torch.Size([256])
module.conv3_1.bn2.running_var 	 torch.Size([256])
module.conv3_1.bn2.num_batches_tracked 	 torch.Size([])
module.conv2_2.conv1.weight 	 torch.Size([128, 384, 3, 3])
module.conv2_2.conv1.bias 	 torch.Size([128])
module.conv2_2.bn1.weight 	 torch.Size([128])
module.conv2_2.bn1.bias 	 torch.Size([128])
module.conv2_2.bn1.running_mean 	 torch.Size([128])
module.conv2_2.bn1.running_var 	 torch.Size([128])
module.conv2_2.bn1.num_batches_tracked 	 torch.Size([])
module.conv2_2.conv2.weight 	 torch.Size([128, 128, 3, 3])
module.conv2_2.conv2.bias 	 torch.Size([128])
module.conv2_2.bn2.weight 	 torch.Size([128])
module.conv2_2.bn2.bias 	 torch.Size([128])
module.conv2_2.bn2.running_mean 	 torch.Size([128])
module.conv2_2.bn2.running_var 	 torch.Size([128])
module.conv2_2.bn2.num_batches_tracked 	 torch.Size([])
module.conv1_3.conv1.weight 	 torch.Size([64, 192, 3, 3])
module.conv1_3.conv1.bias 	 torch.Size([64])
module.conv1_3.bn1.weight 	 torch.Size([64])
module.conv1_3.bn1.bias 	 torch.Size([64])
module.conv1_3.bn1.running_mean 	 torch.Size([64])
module.conv1_3.bn1.running_var 	 torch.Size([64])
module.conv1_3.bn1.num_batches_tracked 	 torch.Size([])
module.conv1_3.conv2.weight 	 torch.Size([64, 64, 3, 3])
module.conv1_3.conv2.bias 	 torch.Size([64])
module.conv1_3.bn2.weight 	 torch.Size([64])
module.conv1_3.bn2.bias 	 torch.Size([64])
module.conv1_3.bn2.running_mean 	 torch.Size([64])
module.conv1_3.bn2.running_var 	 torch.Size([64])
module.conv1_3.bn2.num_batches_tracked 	 torch.Size([])
module.conv0_4.conv1.weight 	 torch.Size([32, 96, 3, 3])
module.conv0_4.conv1.bias 	 torch.Size([32])
module.conv0_4.bn1.weight 	 torch.Size([32])
module.conv0_4.bn1.bias 	 torch.Size([32])
module.conv0_4.bn1.running_mean 	 torch.Size([32])
module.conv0_4.bn1.running_var 	 torch.Size([32])
module.conv0_4.bn1.num_batches_tracked 	 torch.Size([])
module.conv0_4.conv2.weight 	 torch.Size([32, 32, 3, 3])
module.conv0_4.conv2.bias 	 torch.Size([32])
module.conv0_4.bn2.weight 	 torch.Size([32])
module.conv0_4.bn2.bias 	 torch.Size([32])
module.conv0_4.bn2.running_mean 	 torch.Size([32])
module.conv0_4.bn2.running_var 	 torch.Size([32])
module.conv0_4.bn2.num_batches_tracked 	 torch.Size([])
module.final.weight 	 torch.Size([2, 32, 1, 1])
module.final.bias 	 torch.Size([2])
